<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.15"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>QNLP: /Users/mlxd/Desktop/intel-qnlp-rc2/modules/py/scripts/QNLP_Overlap.py Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">QNLP
   &#160;<span id="projectnumber">v1.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.15 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('a00143_source.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">QNLP_Overlap.py</div>  </div>
</div><!--header-->
<div class="contents">
<a href="a00143.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno"><a class="line" href="a00215.html">    1</a></span>&#160;<span class="comment">#!/usr/bin/env python</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment"># coding: utf-8</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"># # Calculating sentence similarity using a hybrid classical-quantum workflow</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"># ### Lee J. O&#39;Riordan and Myles Doyle</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment"># This notebook will serve to demonstrate a mixed hybrid workflow to examine </span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment"># relationships between words, and respective sentence meanings using classical </span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment"># and quantum information processing techniques.</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment"># Our goal is to analyse a corpus, extract key features rom it, and represent </span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment"># those features in a quantum-compatible notation. We proceed to encide these </span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment"># features into a quantum simulation environment using Intel-QS (formerly qHiPSTER),</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment"># and query for similarities using the encoded quantum states. For this, we have </span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment"># implemented various encoding and analysis strategies. Our primary method for </span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="comment"># similarity uses a Hamming distance approach, wherein we apply a simplified </span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="comment"># digital-to-analogue encoding strategy to allow the results to be obtained via</span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="comment"># measurement.</span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="comment"># We must load the Python QNLP packages &amp; module (`QNLP`), and the C++-Python </span></div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="comment"># bound simulator backend and algorithms (`PyQNLPSimulator`).</span></div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="keyword">from</span> mpi4py <span class="keyword">import</span> MPI</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="keyword">from</span> PyQNLPSimulator <span class="keyword">import</span> PyQNLPSimulator <span class="keyword">as</span> p</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="keyword">import</span> QNLP <span class="keyword">as</span> q</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="keyword">from</span> QNLP <span class="keyword">import</span> DisCoCat</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="keyword">from</span> <a class="code" href="a00191.html">QNLP.encoding</a> <span class="keyword">import</span> simple</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="keyword">from</span> <a class="code" href="a00206.html">QNLP.proc.VerbGraph</a> <span class="keyword">import</span> VerbGraph <span class="keyword">as</span> vg</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="keyword">from</span> <a class="code" href="a00202.html">QNLP.proc.HammingDistance</a> <span class="keyword">import</span> HammingDistance</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="keyword">import</span> networkx <span class="keyword">as</span> nx</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="keyword">import</span> sys</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="keyword">import</span> os</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="keyword">from</span> itertools <span class="keyword">import</span> product</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="keyword">import</span> tempfile</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;</div><div class="line"><a name="l00041"></a><span class="lineno"><a class="line" href="a00215.html#a708b3d6881d5091781858aff92b22716">   41</a></span>&#160;comm = MPI.COMM_WORLD</div><div class="line"><a name="l00042"></a><span class="lineno"><a class="line" href="a00215.html#a06bf7b5f4e650ca5e62157be5fce7bdd">   42</a></span>&#160;rank = comm.Get_rank()</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="keywordflow">try</span>:</div><div class="line"><a name="l00044"></a><span class="lineno"><a class="line" href="a00215.html#a059c959a22a944060a86cc97ec6f575c">   44</a></span>&#160;    NUM_BASIS_NOUN = int(os.environ[<span class="stringliteral">&#39;NUM_BASIS_NOUN&#39;</span>])</div><div class="line"><a name="l00045"></a><span class="lineno"><a class="line" href="a00215.html#a0607a72d2a3b6adfbfc6809527aee774">   45</a></span>&#160;    NUM_BASIS_VERB = int(os.environ[<span class="stringliteral">&#39;NUM_BASIS_VERB&#39;</span>])</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;</div><div class="line"><a name="l00047"></a><span class="lineno"><a class="line" href="a00215.html#a7b88e20f0708ea1c4d6b6662e55fea89">   47</a></span>&#160;    BASIS_NOUN_DIST_CUTOFF = int(os.environ[<span class="stringliteral">&#39;BASIS_NOUN_DIST_CUTOFF&#39;</span>])</div><div class="line"><a name="l00048"></a><span class="lineno"><a class="line" href="a00215.html#a48223845a2bf48af91657c6455a0317d">   48</a></span>&#160;    BASIS_VERB_DIST_CUTOFF = int(os.environ[<span class="stringliteral">&#39;BASIS_VERB_DIST_CUTOFF&#39;</span>])</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;</div><div class="line"><a name="l00050"></a><span class="lineno"><a class="line" href="a00215.html#adfda0a6eafa96ddab068bfd5a1a9ec05">   50</a></span>&#160;    VERB_NOUN_DIST_CUTOFF = int(os.environ[<span class="stringliteral">&#39;VERB_NOUN_DIST_CUTOFF&#39;</span>])</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;    </div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;<span class="keywordflow">except</span> KeyError <span class="keyword">as</span> e:    </div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;    NUM_BASIS_NOUN = 2</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;    NUM_BASIS_VERB = 2</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;    BASIS_NOUN_DIST_CUTOFF = 2</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;    BASIS_VERB_DIST_CUTOFF = 2</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;    VERB_NOUN_DIST_CUTOFF = 2</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="comment"># Next, we load the corpus file using the vector-space model, defined in the </span></div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="comment"># `VectorSpaceModel` class, specifying the mode of tagging, and whether to </span></div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="comment"># filter out stop-words. For this notebook I have used the Project Gutenberg </span></div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="comment"># [https://www.gutenberg.org/] edition of `Alice in Wonderland`, with simple </span></div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="comment"># replacements to avoid incorrect tagging of elements (mostly standardising </span></div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;<span class="comment"># apostrophes to \&#39; and quotations to \&quot;). </span></div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="keywordflow">if</span> rank == 0:</div><div class="line"><a name="l00069"></a><span class="lineno"><a class="line" href="a00215.html#a8435efdd7e62fb25c4830c0afa5b263d">   69</a></span>&#160;    s_encoder = simple.SimpleEncoder(num_nouns=NUM_BASIS_NOUN, num_verbs=NUM_BASIS_VERB)</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    <span class="keyword">assert</span> (len(sys.argv) &gt; 1)</div><div class="line"><a name="l00071"></a><span class="lineno"><a class="line" href="a00215.html#a428410dbc447ed2818980b5277824fd2">   71</a></span>&#160;    corpus_file=sys.argv[1] </div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    <span class="keywordflow">if</span> <span class="keywordflow">not</span> os.path.isfile(corpus_file):</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;        <span class="keywordflow">print</span> (<span class="stringliteral">&quot;Error: Inputted file does not exist&quot;</span>)</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;        sys.exit()</div><div class="line"><a name="l00075"></a><span class="lineno"><a class="line" href="a00215.html#ad6d8a58246920cdb68b5c4aa00cdb130">   75</a></span>&#160;    vsm = q.VectorSpaceModel.VectorSpaceModel(</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;        corpus_path=corpus_file,</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;        mode=<span class="stringliteral">&quot;l&quot;</span>, </div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;        stop_words=<span class="keyword">True</span>,</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;        encoder = s_encoder,</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;        use_spacy=<span class="keyword">True</span></div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;    )</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;<span class="comment"># From here we can specify the number of basis elements by occurrence in the </span></div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;<span class="comment"># corpus. This will take the `num_basis_elems` most frequently occurring tokens</span></div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;<span class="comment"># in both verb and noun spaces respectively.</span></div><div class="line"><a name="l00086"></a><span class="lineno"><a class="line" href="a00215.html#a184315d428396da486059124a42581ef">   86</a></span>&#160;    basis     = vsm.define_basis({<span class="stringliteral">&#39;verbs&#39;</span> : NUM_BASIS_VERB, <span class="stringliteral">&#39;nouns&#39;</span> : NUM_BASIS_NOUN})</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;<span class="comment"># Next, we aim to sort the mapping of the basis tokens to a binary </span></div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;<span class="comment"># representation for state encoding. By building a graph, and aiming to solve </span></div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;<span class="comment"># the Hamiltonian cycle problem, we can ensure that the tokens are ordered such that any </span></div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;<span class="comment"># nearest-neighbours have the shortest paths. This becomes necessary later when</span></div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;<span class="comment"># encoding information, as any incorrect bit-flips (potentially </span></div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;<span class="comment"># offered by noise), should still allow some similarity to be represented. By </span></div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;<span class="comment"># ordering the tokens by their minimum path lengths we may maintain closeness </span></div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;<span class="comment"># in the presence of errors.</span></div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;</div><div class="line"><a name="l00097"></a><span class="lineno"><a class="line" href="a00215.html#a53fc06e50c52bf72f8ba006746b8d4ef">   97</a></span>&#160;    verb_dist = vsm.sort_basis_tokens_by_dist(<span class="stringliteral">&quot;verbs&quot;</span>, num_basis=NUM_BASIS_VERB)</div><div class="line"><a name="l00098"></a><span class="lineno"><a class="line" href="a00215.html#a7bca0bf5eec3b351beedd3c557bd70fd">   98</a></span>&#160;    noun_dist = vsm.sort_basis_tokens_by_dist(<span class="stringliteral">&quot;nouns&quot;</span>, num_basis=NUM_BASIS_NOUN)</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;<span class="comment"># We now take the previously defined basis elements, and attempt to arrange </span></div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;<span class="comment"># them such that the distance between nearest-neighbours in the corpus is </span></div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;<span class="comment"># minimised. With this, we assign a Gray code value to the basis. This allows </span></div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;<span class="comment"># us to ensure values closer together in the corpus have a shorter Hamming </span></div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;<span class="comment"># distance between them. We make use of the DisCo-inspired compositional model,</span></div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;<span class="comment"># wherein the distances between words dictates their closeness; we use these </span></div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;<span class="comment"># distances to define the edge-weights between nodes (tokens), and hence by </span></div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;<span class="comment"># defining the problem as a TSP, we can find an ordering that ensures Hamming </span></div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;<span class="comment"># distance relates directly to closeness of words.</span></div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;    vsm.assign_indexing(<span class="stringliteral">&quot;nouns&quot;</span>);</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;    vsm.assign_indexing(<span class="stringliteral">&quot;verbs&quot;</span>);</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;<span class="comment"># With the basis tokens correctly ordered, we may now map the other respective </span></div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;<span class="comment"># elements in their space onto these bases. We aim to map the nouns onto the </span></div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;<span class="comment"># noun basis, and likewise for the verbs. This allows us to represent any other</span></div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;<span class="comment"># word in the corpus in the given basis. We may encode arbitrary superposition </span></div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;<span class="comment"># states to represent the tokens, which can be ascribed as a vector-space </span></div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;<span class="comment"># representation model using quantum states.</span></div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;<span class="comment"># For this, we begin by creating a `DisCoCat` object, and use to perform the </span></div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;<span class="comment"># mappings of basis tokens.</span></div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;</div><div class="line"><a name="l00124"></a><span class="lineno"><a class="line" href="a00215.html#adc24e68d8af8b895965602437f56ca13">  124</a></span>&#160;    dcc = DisCoCat.DisCoCat()</div><div class="line"><a name="l00125"></a><span class="lineno"><a class="line" href="a00215.html#aabf146852118447e44db7b30900897c0">  125</a></span>&#160;    mapping_verbs = dcc.map_to_basis(vsm.tokens[<span class="stringliteral">&#39;verbs&#39;</span>] , verb_dist[<span class="stringliteral">&#39;verbs&#39;</span>], basis_dist_cutoff=BASIS_VERB_DIST_CUTOFF)</div><div class="line"><a name="l00126"></a><span class="lineno"><a class="line" href="a00215.html#ab14ba47729b1566f21baf444fdda4646">  126</a></span>&#160;    mapping_nouns = dcc.map_to_basis(vsm.tokens[<span class="stringliteral">&#39;nouns&#39;</span>] , noun_dist[<span class="stringliteral">&#39;nouns&#39;</span>], basis_dist_cutoff=BASIS_NOUN_DIST_CUTOFF)</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;<span class="comment"># For the above data, the meanings of the composite nouns `hall` and `table` can be represented as:</span></div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;<span class="comment"># $$\begin{array}{ll}</span></div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;<span class="comment"># \vert \textrm{hall} \rangle &amp;= a_0\vert \textrm{round} \rangle + a_1\vert \textrm{Rabbit} \rangle + a_2\vert \textrm{head} \rangle + a_3\vert \textrm{way} \rangle + a_4\vert \textrm{time} \rangle + a_5\vert \textrm{Alice} \rangle, \\</span></div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;<span class="comment"># \vert \textrm{table} \rangle &amp;= b_{0}\vert \textrm{March} \rangle  + b_{1}\vert \textrm{tone} \rangle  + b_{2}\vert \textrm{round} \rangle  + b_{3}\vert \textrm{nothing} \rangle  + b_{4}\vert \textrm{Hare} \rangle  + b_{5}\vert \textrm{things} \rangle  + b_{6}\vert \textrm{thing} \rangle  + b_{7}\vert \textrm{way} \rangle  + b_{8}\vert \textrm{King} \rangle  + b_{9}\vert \textrm{time} \rangle  + b_{10}\vert \textrm{Alice} \rangle,</span></div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;<span class="comment"># \end{array}</span></div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;<span class="comment"># $$</span></div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;<span class="comment"># where we assume each item in the basis set has an orthogonal quantum state </span></div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;<span class="comment"># representing it. For the given 32-numbered bases, we can assume the </span></div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;<span class="comment"># coefficient of any unlisted state is represented as zero.</span></div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;<span class="comment"># With nouns mappable to the noun basis set, and verbs mappable to the verbs </span></div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;<span class="comment"># basis set, we may now examine the composite noun-verb-noun sentence </span></div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;<span class="comment"># structures. This involves a similar approach to compositional mapping of </span></div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;<span class="comment"># token to token-basis, wherein composite words close together can be </span></div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;<span class="comment"># considered within the same NVN sentnence, and thus present themselves as a </span></div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;<span class="comment"># constructable entity for binary-string quantum state encoding.</span></div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;<span class="comment"># The following pair-wise relations are required for a fully generalised solution:</span></div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;<span class="comment"># </span></div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;<span class="comment"># $$</span></div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;<span class="comment"># \begin{equation*}</span></div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;<span class="comment"># \begin{array}{l|c|c|c}</span></div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;<span class="comment"># &amp; \textbf{Dataset 1} &amp; \textbf{Dataset 2}  &amp; \textbf{Use} \\</span></div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;<span class="comment"># \hline</span></div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;<span class="comment"># 1.&amp;\textrm{noun basis} &amp; \textrm{noun basis} &amp; \textrm{noun basis binary ordering} \\</span></div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;<span class="comment"># 2.&amp;\textrm{noun composite} &amp; \textrm{noun basis} &amp; \textrm{noun representative meaning} \\</span></div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;<span class="comment"># 3.&amp;\textrm{noun composite} &amp; \textrm{noun composite} &amp; \textrm{inter-noun relationships} \\</span></div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;<span class="comment"># \hline</span></div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;<span class="comment"># 4.&amp;\textrm{verb basis} &amp; \textrm{verb basis} &amp; \textrm{verb basis binary ordering} \\</span></div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;<span class="comment"># 5.&amp;\textrm{verb composite} &amp; \textrm{verb basis} &amp; \textrm{verb representative meaning} \\</span></div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;<span class="comment"># 6.&amp;\textrm{verb composite} &amp; \textrm{verb compsite} &amp; \textrm{inter-verb relationships} \\</span></div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;<span class="comment"># \hline</span></div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;<span class="comment"># 7.&amp;\textrm{noun basis} &amp; \textrm{verb basis} &amp; \textrm{compiled bit-strings for encoding} \\</span></div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;<span class="comment"># 8.&amp;\textrm{noun composite} &amp; \textrm{verb composite} &amp; \textrm{compositional meaning for bit-string generation} \\</span></div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;<span class="comment"># \end{array}</span></div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;<span class="comment"># \end{equation*}</span></div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;<span class="comment"># $$</span></div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;<span class="comment"># Additionally, one may add a more complex parameter exploration space by </span></div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;<span class="comment"># customising the tagging options; here the use of lemmatisation `(mode=&quot;l&quot;)`, </span></div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;<span class="comment"># stemming `(mode=&quot;s&quot;)`, or default tagging options `(mode=None)`, results in </span></div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;<span class="comment"># a different set of words in the above graphs.</span></div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;<span class="comment"># From here, we define our encoding and decoding dictionaries.</span></div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;<span class="comment"># Define basis tokens encoding and decoding dicts</span></div><div class="line"><a name="l00176"></a><span class="lineno"><a class="line" href="a00215.html#ae1c214dd013983368a25c0f13bcf357d">  176</a></span>&#160;    encoding_dict = {<span class="stringliteral">&quot;ns&quot;</span> : vsm.encoded_tokens[<span class="stringliteral">&quot;nouns&quot;</span>],</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;                     <span class="stringliteral">&quot;v&quot;</span>  : vsm.encoded_tokens[<span class="stringliteral">&quot;verbs&quot;</span>],</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;                     <span class="stringliteral">&quot;no&quot;</span> : vsm.encoded_tokens[<span class="stringliteral">&quot;nouns&quot;</span>]</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;                    }</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;</div><div class="line"><a name="l00181"></a><span class="lineno"><a class="line" href="a00215.html#acf38f1db5e31ddfce6dd36ac3130c0e8">  181</a></span>&#160;    decoding_dict = {<span class="stringliteral">&quot;ns&quot;</span> : { v:k <span class="keywordflow">for</span> k,v <span class="keywordflow">in</span> encoding_dict[<span class="stringliteral">&quot;ns&quot;</span>].items() },</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;                      <span class="stringliteral">&quot;v&quot;</span>  : { v:k <span class="keywordflow">for</span> k,v <span class="keywordflow">in</span> encoding_dict[<span class="stringliteral">&quot;v&quot;</span>].items() },</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;                     <span class="stringliteral">&quot;no&quot;</span> : { v:k <span class="keywordflow">for</span> k,v <span class="keywordflow">in</span> encoding_dict[<span class="stringliteral">&quot;no&quot;</span>].items() }</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;                    }</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;<span class="comment"># With the above information, we can now determine the required resources to </span></div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;<span class="comment"># store our data in a qubit register.</span></div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;<span class="comment"># Register must be large enough to support 2*|nouns| + |verbs| in given encoding</span></div><div class="line"><a name="l00190"></a><span class="lineno"><a class="line" href="a00215.html#a325027b1493c42cce2f1dac531bcb1a8">  190</a></span>&#160;    len_reg_memory =    q.encoding.utils.pow2bits( int(np.max( list(encoding_dict[<span class="stringliteral">&#39;v&#39;</span>].values()))) )[1] + \</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;                        q.encoding.utils.pow2bits( int(np.max( list(encoding_dict[<span class="stringliteral">&#39;no&#39;</span>].values()))) )[1] + \</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;                        q.encoding.utils.pow2bits( int(np.max( list(encoding_dict[<span class="stringliteral">&#39;ns&#39;</span>].values()))) )[1] </div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;</div><div class="line"><a name="l00194"></a><span class="lineno"><a class="line" href="a00215.html#ac609f7145bd16ffb96d5a37ccde7ee68">  194</a></span>&#160;    len_reg_aux = len_reg_memory + 2</div><div class="line"><a name="l00195"></a><span class="lineno"><a class="line" href="a00215.html#aa788128e200f2c0662a1a11d99126894">  195</a></span>&#160;    num_qubits = len_reg_memory + len_reg_aux</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;    print(<span class="stringliteral">&quot;&quot;&quot;{}</span></div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;<span class="stringliteral">Requires {} qubits to encode data using {} </span></div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;<span class="stringliteral">noun and {} verb basis elements, allowing a </span></div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;<span class="stringliteral">maximum of {} unique patterns.</span></div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;<span class="stringliteral">{}</span></div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;<span class="stringliteral">&quot;&quot;&quot;</span>.format(<span class="stringliteral">&quot;#&quot;</span>*48, num_qubits, NUM_BASIS_NOUN, NUM_BASIS_VERB, (NUM_BASIS_NOUN**2)*NUM_BASIS_VERB, <span class="stringliteral">&quot;#&quot;</span>*48)</div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;    )</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;<span class="comment"># Using encoded bitstrings for bases, look-up mapping terms for composite nouns</span></div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;<span class="comment"># and verbs, create bitstrings and generate quantum states.</span></div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;</div><div class="line"><a name="l00208"></a><span class="lineno"><a class="line" href="a00215.html#a91b8f6ad297ce51c2d32b75cf2305332">  208</a></span>&#160;    corpus_list_n = vsm.tokens[<span class="stringliteral">&#39;nouns&#39;</span>]</div><div class="line"><a name="l00209"></a><span class="lineno"><a class="line" href="a00215.html#a1761f6e9cdba22876c7653b10c14b06b">  209</a></span>&#160;    corpus_list_v = vsm.tokens[<span class="stringliteral">&#39;verbs&#39;</span>]</div><div class="line"><a name="l00210"></a><span class="lineno"><a class="line" href="a00215.html#a206cc90f74056b29cea51f2e2abf2ce3">  210</a></span>&#160;    dist_cutoff = BASIS_VERB_DIST_CUTOFF</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;</div><div class="line"><a name="l00212"></a><span class="lineno"><a class="line" href="a00215.html#a3b083f012c37923d7786045eaa159b07">  212</a></span>&#160;    v_list = vg.calc_verb_noun_pairings(corpus_list_v, corpus_list_n, VERB_NOUN_DIST_CUTOFF)</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;</div><div class="line"><a name="l00214"></a><span class="lineno"><a class="line" href="a00215.html#af3bbd71f6a29e0fd53515a6104385406">  214</a></span>&#160;    sentences = []</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;    <span class="keywordflow">for</span> v <span class="keywordflow">in</span> v_list:</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;        <span class="keywordflow">for</span> i <span class="keywordflow">in</span> v.lr_nouns.keys(): <span class="comment">#product(v.left_nouns, [v.verb], v.right_nouns):</span></div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;        <span class="comment">#ns,s,no = mapping_nouns[i[0]], mapping_verbs[i[1]], mapping_nouns[i[2]]</span></div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;        <span class="comment">#if v.left_nouns != None and v.right_nouns != None:</span></div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;            <span class="keywordflow">if</span> mapping_nouns[i[0]] != <span class="keywordtype">None</span> <span class="keywordflow">and</span> mapping_verbs[v.verb] != <span class="keywordtype">None</span> <span class="keywordflow">and</span> mapping_nouns[i[1]] != <span class="keywordtype">None</span>:</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;                sentences.append(</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;                    [   {i[0] : [encoding_dict[<span class="stringliteral">&#39;ns&#39;</span>][k] <span class="keywordflow">for</span> k <span class="keywordflow">in</span> mapping_nouns[i[0]].keys()] },</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;                        {v.verb : [encoding_dict[<span class="stringliteral">&#39;v&#39;</span>][k] <span class="keywordflow">for</span> k <span class="keywordflow">in</span> mapping_verbs[v.verb].keys()] },</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;                        {i[1] : [encoding_dict[<span class="stringliteral">&#39;no&#39;</span>][k] <span class="keywordflow">for</span> k <span class="keywordflow">in</span> mapping_nouns[i[1]].keys()] }</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;                    ]</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;                )</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;    sentences</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;    print(<span class="stringliteral">&quot;Sentences matching noun-verb-noun structure captured as:&quot;</span>, sentences)</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;    <span class="comment"># Set up registers to store indices</span></div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;    <span class="comment"># Keeping aux register and control registers in these positions</span></div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;    <span class="comment"># to reduce overhead during encoding stages. ~25% faster than data-aux-control</span></div><div class="line"><a name="l00233"></a><span class="lineno"><a class="line" href="a00215.html#a473e17fd0e1b36555f05bc6a8dc26525">  233</a></span>&#160;    reg_memory = [0]*len_reg_memory;</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len_reg_memory):</div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;        reg_memory[i] = i + len_reg_aux</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;</div><div class="line"><a name="l00237"></a><span class="lineno"><a class="line" href="a00215.html#a3712efe39e25310a62f2f83450548443">  237</a></span>&#160;    reg_aux = [0]*len_reg_aux</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(len_reg_aux-2):</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;        reg_aux[i] = i + 2</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;    reg_aux[-2] = 0</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;    reg_aux[-1] = 1</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;    print(<span class="stringliteral">&quot;REG_MEM=&quot;</span>,reg_memory)</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;    print(<span class="stringliteral">&quot;REG_AUX=&quot;</span>,reg_aux)</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;    </div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;<span class="comment">#Create list for the patterns to be encoded</span></div><div class="line"><a name="l00246"></a><span class="lineno"><a class="line" href="a00215.html#a9cab05003dd96443c003fb207ad6e5f9">  246</a></span>&#160;    vec_to_encode = []</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;<span class="comment"># Generate bit-patterns from sentences and store in vec_to_encode</span></div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;    <span class="keywordflow">for</span> idx,sentence <span class="keywordflow">in</span> enumerate(sentences):</div><div class="line"><a name="l00251"></a><span class="lineno"><a class="line" href="a00215.html#aa1e04738dfbdaad58a11fcce8d39a8eb">  251</a></span>&#160;        superpos_patterns = list( product( list(sentence[0].values())[0], list(sentence[1].values())[0], list(sentence[2].values())[0] ) )</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;        <span class="comment"># Generate all combinations of the bit-patterns for superpos states</span></div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;        <span class="keywordflow">for</span> patt <span class="keywordflow">in</span> superpos_patterns: </div><div class="line"><a name="l00254"></a><span class="lineno"><a class="line" href="a00215.html#ad46953802b616f6b2cb7944b88e0ddfa">  254</a></span>&#160;            num = q.utils.encode_binary_pattern_direct(patt, encoding_dict)</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;            vec_to_encode.extend([num])</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;<span class="comment">#Need to remove duplicates        </span></div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;    vec_to_encode = list(set(vec_to_encode))</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;    vec_to_encode.sort()</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;</div><div class="line"><a name="l00261"></a><span class="lineno"><a class="line" href="a00215.html#a59a2429d6b626570a57d45a1f3ac1c6b">  261</a></span>&#160;    d ={<span class="stringliteral">&quot;sentences&quot;</span> : len(sentences),</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;        <span class="stringliteral">&quot;patterns&quot;</span> : len(vec_to_encode),</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;        <span class="stringliteral">&quot;NUM_BASIS_NOUN&quot;</span> : NUM_BASIS_NOUN,</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;        <span class="stringliteral">&quot;NUM_BASIS_VERB&quot;</span> : NUM_BASIS_VERB,</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;        <span class="stringliteral">&quot;BASIS_NOUN_DIST_CUTOFF&quot;</span> : BASIS_NOUN_DIST_CUTOFF,</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;        <span class="stringliteral">&quot;BASIS_VERB_DIST_CUTOFF&quot;</span> : BASIS_VERB_DIST_CUTOFF,</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;        <span class="stringliteral">&quot;VERB_NOUN_DIST_CUTOFF&quot;</span> : VERB_NOUN_DIST_CUTOFF </div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;    }</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;    print(d)</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;    print(<span class="stringliteral">&quot;Encoding data:&quot;</span>, vec_to_encode)</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;    <span class="comment"># Counter for experiment results; key exists for each potentially unique outcome defined by encoding</span></div><div class="line"><a name="l00273"></a><span class="lineno"><a class="line" href="a00215.html#a32a2b3946217bbe60ccb1fc46d902f2f">  273</a></span>&#160;    shot_counter = {}</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> vec_to_encode:</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;        shot_counter.update({i : 0})</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;<span class="comment">#    from IPython import embed; embed()</span></div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;<span class="keywordflow">else</span>:</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;    reg_memory = <span class="keywordtype">None</span></div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;    reg_aux = <span class="keywordtype">None</span></div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;    len_reg_memory = <span class="keywordtype">None</span></div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;    vec_to_encode = <span class="keywordtype">None</span></div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;    shot_counter = <span class="keywordtype">None</span></div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;    encoding_dict = <span class="keywordtype">None</span></div><div class="line"><a name="l00287"></a><span class="lineno"><a class="line" href="a00215.html#ab2a788d52ec4683dea59bccdbf3b9422">  287</a></span>&#160;    bit_shifts = <span class="keywordtype">None</span></div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;reg_memory = comm.bcast(reg_memory, root=0)</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;reg_aux = comm.bcast(reg_aux, root=0)</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;vec_to_encode = comm.bcast(vec_to_encode, root=0)</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;shot_counter = comm.bcast(shot_counter, root=0)</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;encoding_dict = comm.bcast(encoding_dict, root=0)</div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;num_qubits = len(reg_memory) + len(reg_aux)</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;<span class="comment">#Explicitly disable fusion as it can cause incorrect results</span></div><div class="line"><a name="l00298"></a><span class="lineno"><a class="line" href="a00215.html#a156eab79c797c8eb9127a0879d3d6999">  298</a></span>&#160;use_fusion = <span class="keyword">False</span></div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;<span class="keywordflow">if</span> os.environ.get(<span class="stringliteral">&#39;RESOURCE_EST&#39;</span>) <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;    print(<span class="stringliteral">&quot;Overriding default qubit count&quot;</span>)</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;    num_qubits = 1</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;</div><div class="line"><a name="l00304"></a><span class="lineno"><a class="line" href="a00215.html#a8134e2d72c19193c4fbadd69343daecc">  304</a></span>&#160;sim1 = p(num_qubits, use_fusion)</div><div class="line"><a name="l00305"></a><span class="lineno"><a class="line" href="a00215.html#a7d358f2b9f72fcc4fe1e40d260e8c355">  305</a></span>&#160;sim2 = p(num_qubits, use_fusion)</div><div class="line"><a name="l00306"></a><span class="lineno"><a class="line" href="a00215.html#a8473da92757e159d924ade0088279ec0">  306</a></span>&#160;normalise = <span class="keyword">True</span></div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;<span class="keywordflow">if</span> rank == 0:</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;    <span class="keywordflow">try</span>:</div><div class="line"><a name="l00310"></a><span class="lineno"><a class="line" href="a00215.html#a06816342e6752328d31e75a6fa02fe63">  310</a></span>&#160;        num_exps = int(sys.argv[2])</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;    <span class="keywordflow">except</span> Exception <span class="keyword">as</span> e:</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;        num_exps = 10</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;</div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;<span class="keywordflow">else</span>:</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;    num_exps = <span class="keywordtype">None</span></div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;num_exps=comm.bcast(num_exps, root=0)</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;</div><div class="line"><a name="l00319"></a><span class="lineno"><a class="line" href="a00215.html#a87107a4cf8576fdccabdd1e624ab6c18">  319</a></span>&#160;num_faults = 0</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;<span class="comment"># Use all potential string patterns as test</span></div><div class="line"><a name="l00322"></a><span class="lineno"><a class="line" href="a00215.html#a0cd060d5b59a698d572c1c804a54f966">  322</a></span>&#160;test_strings = list(product(encoding_dict[<span class="stringliteral">&quot;ns&quot;</span>].values(), encoding_dict[<span class="stringliteral">&quot;v&quot;</span>].values(), encoding_dict[<span class="stringliteral">&quot;no&quot;</span>].values()))</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;<span class="keywordflow">for</span> i_ts1,ts1 <span class="keywordflow">in</span> enumerate(test_strings[:-1]):</div><div class="line"><a name="l00326"></a><span class="lineno"><a class="line" href="a00215.html#af426b4770730134873cd65bce431a73f">  326</a></span>&#160;    test_pattern1 = q.utils.encode_binary_pattern_direct(ts1, encoding_dict)</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;    <span class="keywordflow">if</span> test_pattern1 <span class="keywordflow">in</span> vec_to_encode:</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;        <span class="keywordflow">if</span> rank == 0:</div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;            print(<span class="stringliteral">&quot;Pattern {} already exists. Skipping&quot;</span>.format(test_pattern1))</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;            sys.stdout.flush()</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;        <span class="keywordflow">continue</span></div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;    <span class="keywordflow">for</span> i_ts2,ts2 <span class="keywordflow">in</span> enumerate(test_strings[i_ts1+1:]):</div><div class="line"><a name="l00334"></a><span class="lineno"><a class="line" href="a00215.html#a0fa9dd4c43ef343321654c29c20828d9">  334</a></span>&#160;        test_pattern2 = q.utils.encode_binary_pattern_direct(ts2, encoding_dict)</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;        <span class="keywordflow">if</span> test_pattern2 <span class="keywordflow">in</span> vec_to_encode:</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;            <span class="keywordflow">if</span> rank == 0:</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;                print(<span class="stringliteral">&quot;Pattern {} already exists. Skipping encoding of {} and {}&quot;</span>.format(test_pattern2, test_pattern1, test_pattern2))</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;                sys.stdout.flush()</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;            <span class="keywordflow">continue</span></div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;</div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;        sim1.initRegister()</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;        sim2.initRegister()</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;    <span class="comment"># Encode</span></div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;        sim1.encodeBinToSuperpos_unique(reg_memory, reg_aux, vec_to_encode, len(reg_memory))</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;        sim2.encodeBinToSuperpos_unique(reg_memory, reg_aux, vec_to_encode, len(reg_memory))</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;<span class="comment"># Compute Hamming distance between test pattern and encoded patterns</span></div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;        sim1.applyHammingDistanceRotY(test_pattern1, reg_memory, reg_aux, len(reg_memory))</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;        sim2.applyHammingDistanceRotY(test_pattern2, reg_memory, reg_aux, len(reg_memory))</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;</div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;    <span class="comment"># Measure</span></div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;        sim1.collapseToBasisZ(reg_aux[len(reg_aux)-2], 1)</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;        sim2.collapseToBasisZ(reg_aux[len(reg_aux)-2], 1)</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;</div><div class="line"><a name="l00357"></a><span class="lineno"><a class="line" href="a00215.html#a3af218e3b7211e6b4cb15b7a4e3715c5">  357</a></span>&#160;        val = sim1.overlap(sim2)</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;        <span class="keywordflow">if</span> rank==0:</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;            print(<span class="stringliteral">&quot;|&lt;{}|{}&gt;|^2,|&lt;{}|{}&gt;|^2,{}&quot;</span>.format(test_pattern1, test_pattern2, test_string1, test_string2, np.abs(val)**2))</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;            sys.stdout.flush()</div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;MPI.Finalize()</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;exit()</div><div class="ttc" id="a00191_html"><div class="ttname"><a href="a00191.html">QNLP.encoding</a></div><div class="ttdef"><b>Definition:</b> <a href="a01313_source.html#l00001">__init__.py:1</a></div></div>
<div class="ttc" id="a00206_html"><div class="ttname"><a href="a00206.html">QNLP.proc.VerbGraph</a></div><div class="ttdef"><b>Definition:</b> <a href="a00119_source.html#l00001">VerbGraph.py:1</a></div></div>
<div class="ttc" id="a00202_html"><div class="ttname"><a href="a00202.html">QNLP.proc.HammingDistance</a></div><div class="ttdef"><b>Definition:</b> <a href="a00107_source.html#l00001">HammingDistance.py:1</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_da17d78632561013a94c09e29a703cf4.html">intel-qnlp-rc2</a></li><li class="navelem"><a class="el" href="dir_1ee3393be4a977752a56b41968766bfc.html">modules</a></li><li class="navelem"><a class="el" href="dir_f079078911bee6a986813e8b27e07cbe.html">py</a></li><li class="navelem"><a class="el" href="dir_0f22e3192e65c8d779f74b8b47331429.html">scripts</a></li><li class="navelem"><a class="el" href="a00143.html">QNLP_Overlap.py</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.15 </li>
  </ul>
</div>
</body>
</html>
