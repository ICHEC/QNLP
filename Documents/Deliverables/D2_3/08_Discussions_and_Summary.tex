\section{Discussions and Summary}
\label{sec:discussion_and_summary}

In this document we have discussed the complete workflow of the application including the Python bindings of the C++ layer which allows for the execution of the entire application in Python. A new basis word encoding strategy that takes the relative differences in the meanings of the basis words into account for the encoding was introduced and has been implemented. The QNLP library and by extension the application has now been successfully implemented with MPI enabled which allows for scaling of the application to larger problem sizes. MPI can also be used for the application's Python workflow which uses mpi4py to setup the environment which is then used in the C++ back-end. Optimisations have been implemented to the \textit{nCU} routine which decrease the number of gate calls by an order of magnitude, thus significantly increasing the performance. This optimisation is still in progress, but it almost complete. The application was profiled, identifying bottleknecks in the application and the Intel\textregistered-QS. As discussed, the \textit{nCU} bottleneck is being addressed, however the bottlenecks due to the Intel\textregistered-QS are beyond the scope of this project. Finally, strong scaling experiments were conducted for the application. It was observed that it is worth utilising the maximum allowed processes per node to increase performance. Thus, $32$ processes per node should be used. There is no significant MPI overhead between nodes that does not exist on a single node for relatively small problem sizes. The application was observed to scale quite well for small problem sizes, however scaling quickly becomes a significant issue as the problem size increases. Further scaling experiments will be conducted for the optimised \textit{nCU} implementation of the application.