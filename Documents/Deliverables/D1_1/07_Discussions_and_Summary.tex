\section{Discussions and Summary}
\label{sec:discussion_and_summary}
Beginning with an outline of our proposed algorithmic approach in Section~\ref{sec:abstraction_of_disco_algorithms}, we discussed the steps required to realise the DisCo models for closest vector and sentence similarity from an implementation independent approach. The use of pre-computation allows us to effectively prepare our data into a format that may be represented in a quantum state. The pre-computed data may then be encoded into a quantum state using a viable method. Following this, we may directly use the closest vector, or sentence similarity algorithms as discussed by 
Zeng and Coecke~\cite{Zeng_Coecke_2016}.

We proceed to mention issues encountered with the state creation approach as proposed in the original work, where the use of QRAM models in quantum algorithm design presents challenges to small-scale count quantum computer systems and simulators with limited number of qubits. Workarounds for this were introduced, following the encoding approach of Trugenburger~\cite{Trugenberger_2001}, with the use of Hamming distance methods being effective to determine quantum state distance measures. 

An outline of the software architecture is proposed, wherein we make use of a two-tiered approach to perform pre-computation (implemented using Python) and subsequent encoding and evaluation (implemented using C++). Intel qHiPSTER is used within this latter layer to realise the quantum computing aspects of the described algorithms.

Our proposed testing and evaluation methodology is presented, and forms an outline for our design decisions. We aim for a granular procedure, wherein testing and evaluation follows a \emph{unit-integration-regression-acceptance} layout.

%Methodologies for testing and evaluating the implementation are outlined as well as a means to seamlessly apply continuous integration of these tests. This will allow for easy collection of additional performance metrics. We define the acceptance metrics for the implementation's results so that they can be validated.

The system requirements and software dependencies for the Intel Quantum Simulator are detailed. The simulator was observed to scale well for both weak and strong scaling. However, the limitations of the scaling for larger problem sizes are noted. A limited proposed workaround and the expected drawbacks are described; using a large node allocation on a bigger HPC cluster.

The next steps of this project involve implementing the algorithms and methods described in this report. After these algorithms have been implemented and their results are validated, we must integrate the different algorithms into a single software solution -- firstly, combining components of the Python and C++ implementations into modules, and following this integrating the Python and C++ modules to form one seamless application as illustrated in Figure~\ref{fig:qnlp_controlflow}. The results must be validated for the different corpora, which may require further refinement of the implementation. These steps will form the majority of the remaining work.

Furthermore, if time permits, different approaches to some of the above algorithms will be explored in greater detail. These algorithms involve an alternative to the DisCo model outlined in Appendix~\ref{app:loco_algo}, a Durr-Hoyer optimization of the Hamming distance approach in Appendix~\ref{app:hamming_dh}, and finally a state-rotation method for use with measurement-based state determination in Appendix \ref{app:ry_phase}.