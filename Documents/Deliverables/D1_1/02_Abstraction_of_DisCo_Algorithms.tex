\section{Abstraction of DisCo Algorithms}
\label{sec:abstraction_of_disco_algorithms}
To implement the DisCo model algorithms, we first consider the mappings between DisCo's graphical notation and quantum Dirac notation. Figure~\ref{fig:disco_dirac} represents the meaning space and mappings necessary to understand the sentence ``\textsc{Mary likes John}'', and follows directly from the work of Coecke et al. \cite{Coecke_Sadrzadeh_Clark_2010}. Above the dotted line, the blue triangles indicate each component (word) of the sentence. The lines beneath the sentence entities indicate the space in which their meanings exist; \textbf{P} and \textbf{P$^*$} indicate the meaning space of nouns and their conjugates, \textbf{S} is the overall meaning of the sentence, and verbs exist in the composite meaning space of \textsc{noun-sentence-noun}. Below the dotted line, connecting these wires allows us to perform computations on this abstract formalism, and is akin to contractions over tensor-network diagrams commonly used in condensed matter systems~\cite{ Coecke_Paquette_Pavlovic_2009,Biamonte_Clark_Jaksch_2011}. By performing these ``U''-shaped wirings, we contract these tensor indices, with the remaining free-index in the space \textbf{S} (the sentence meaning).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{D1_1/Images/MappingDisCo.pdf}
    \caption{Structural mapping of DisCo graphical notation to quantum Dirac notation. }
    \label{fig:disco_dirac}
\end{figure}

This approach will require implementations of text-analysis, resource allocations, and mappings between the generated quantum states. We aim to develop a framework to ensure these mappings for sentence state-creation and meaning extraction are at high-level to enable ease of extensibility and development for more complex sentence structures. We propose the following algorithmic layout to overseeing the implementation of this work.

Algorithm~\ref{algo:tagging} is used to tokenise and tag the text in a given corpus. Using this, we can determine in which respective space a token (word) exists, as shown by the wiring in Figure~\ref{fig:disco_dirac} and create the appropriate quantum state to represent its meaning.

%%Pseudocode for corpus to tags and encodings
\begin{algorithm}\label{algo:tagging}
    \KwData{corpus strings}
    \KwResult{data encodings, tagged words, and meaning-spaces }
    load corpus strings\;
    tokenise corpus strings\;
    \While{not processed all corpus tokens}{
        read current token\;
        \uIf{token $\in~\{\,x \mid x \textrm{ is a noun}\,\}$}{
            tag token as noun\;
            }
        \uElseIf{token $\in~\{\,x \mid x \textrm{ is a verb}\,\}$}{
            tag token as verb\;
        }
        \Else{
            ignore token\;
        }
        generate unique bit-string encoding for token\;
        add tagged token to the tagged set\;
        token $\rightarrow$ next token\;
    }
    write tagged and encoded tokens to external DB\;
    \caption{Corpus to meaning-space tagging and encoding}
\end{algorithm}

\newpage
Following this step, we use Algorithm~\ref{algo:encoding} to generate the necessary quantum gate operations to encode the corpus data. This generates the quantum state with the encoded meanings, again as presented by Figure~\ref{fig:disco_dirac}. With this state, we can now examine the closest vectors and sentence similarities, through appropriately ``wiring'' test states to the resulting quantum state.

%%Pseudocode for encodings to state construction
\begin{algorithm}\label{algo:encoding}
    \KwData{tagged and encoded tokens, }
    \KwResult{quantum state representation of meaning-space }
    load tagged and encoded data, $D$\;
    initialise data quantum register, $\vert D\rangle$ to $\vert 00\cdots 0\rangle$\;
    \For{$i\leftarrow D[1]$ \KwTo $D[n]$ }{
        generate quantum gate sequence to realise $D[i]$ in quantum circuit\;
        apply gate sequence to update $\vert D\rangle$ state with $D[i]$ data\;
    }
    \caption{Corpus meaning-space quantum state creation}
\end{algorithm}

% \todo{Closest vector model}
% \todo{Sentence similarity}

Following the decomposition of a corpus using Algorithm~\ref{algo:tagging} and subsequent encoding using Algorithm~\ref{algo:encoding}, we use Algorithm~\ref{algo:closest_vector} to evaluate the closest vector for a given encoded data set with their quantum states. Algorithm~\ref{algo:closest_vector} presents a method for distance calculation between a test data vector (state) and the encoded data, and returns the representative vector (state) with closest meaning to that of the test as the output. By appropriately training the encoding data, we can affect the result, and as such different text corpora will likely produce different resulting values.

%%DisCo closest vector
\begin{algorithm}\label{algo:closest_vector}
    \KwData{quantum state representation of meaning-space $\vert \Psi \rangle$, quantum state representation of test token $\vert s \rangle$ }
    \KwResult{quantum state representation of meaning-space $\vert \Psi \rangle $ with amplitudes proportional to the distance between $\vert s \rangle $ and each state in $\vert \Psi \rangle$}
    load $\vert \Psi \rangle$ using Algorithm~\ref{algo:encoding}\;
    similarly load $ \vert s \rangle$ into separate register\;
    update amplitudes using distance calculation between $\vert s \rangle$ and each state in $\vert \Psi \rangle$;
    \caption{Closest vector problem using the DisCo framework.}
\end{algorithm}

\newpage
As a natural extension to Algorithm~\ref{algo:closest_vector}, we may encode a variety of test and data states, and determine their similarity through an inner-product evaluation, defined by Algorithm~\ref{algo:csc}.

%%DisCo sentence similarity
\begin{algorithm}\label{algo:csc}
    \KwData{quantum state data tags and tokens, \textsc{O}$_d$}
    \KwData{quantum state test tags and tokens, \textsc{O}$_t$}
    \KwResult{numerical similarity between sentences trained on corpus data}
    allocate quantum register, $\vert \Psi \rangle$ of length $2n+2$\;
    \ForEach{token $j \in \textsc{O}_d$ }{
        encode $j$ into $\vert \Psi \rangle$ using Algorithm~\ref{algo:encoding} for indices $1\rightarrow n$
    }
    \ForEach{token $k \in \textsc{O}_t$ }{
        encode $k$ into $\vert \Psi \rangle$ using Algorithm~\ref{algo:encoding} for indices $n+1\rightarrow 2n$
    }
    use Algorithm~\ref{algo:closest_vector} to compare test with encoded data\;
    return inner-product value of comparison\;
    \caption{Sentence similarity problem using the DisCo framework}
\end{algorithm}
