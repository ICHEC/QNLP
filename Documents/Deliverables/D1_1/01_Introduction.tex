\section{Introduction}
\label{sec:introduction}
% General introduction to NLP - overview of the problem addressed in this project - quantum advantage for this problem - rest of the document
\subsection{Natural Language Processing and Quantum Advantage}
Natural language processing (NLP) is often used to perform tasks such as machine translation, sentiment analysis, relationship extraction, word sense disambiguation and automatic summary generation. Most traditional NLP algorithms for these problems are defined to operate over strings of words, and are commonly referred to as the “bag of words” approach. The challenge, and thus limitation, of this approach is that the algorithms analyse sentences in a corpus based on meanings of the component words and lack information from the grammatical rules and nuances of the language. Consequently, the qualities of results of these traditional algorithms are often unsatisfactory when the complexity of the problem increases.

On the other hand, an alternate approach called ``compositional semantics” incorporates the grammatical structure of sentences in a language into the analysis algorithms. Compositional semantics algorithms include the information flows between words in a sentence to determine the meaning of the whole sentence. One such model is “distributional compositional semantics” (DisCo) \cite{Zeng_Coecke_2016}, which is based on tensor product composition to give a grammatically informed algorithm that computes the meaning of sentences and phrases. This algorithm has been noted to potentially offer improvements to the quality of results, particularly for more complex sentences, in terms of memory and computational requirements. However, the main challenge in its implementation is the need for large classical computational resources.

For instance, given a corpus whose word meaning space is based on 2000 most common words, Table~\ref{tab:quantum_advantage_for_storage} presents the comparison between classical and quantum storage requirements \cite{Zeng_Coecke_2016}.

\begin{table}[!ht]
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
    \multicolumn{3}{|c|}{Classical vs. Quantum Storage Requirements} \\
    \hline \hline
              & 1 transitive verb & 10K transitive verbs \\
    \hline
    Classical & 1 GB              & 10 TB \\
    Quantum   & 33 qubits         & 47 qubits \\
    \hline
  \end{tabular}
  \caption{Quantum Advantage for Storage}
  \label{tab:quantum_advantage_for_storage}
\end{table}

\subsection{Objective}
The distributional compositional semantics (DisCo) model was originally developed by its authors with direct inspiration from quantum theory, and present the quantum version of the DisCo model based on two algorithms~\cite{Zeng_Coecke_2016}:
\begin{itemize}
  \item \textbf{Closest vector problem}: An algorithm for the “closest vector problem” is used to determine the word/phrase out of a set of words/phrases that has the closest relation (for instance, meaning) to a given word/phrase. This finds application in many computational linguistic tasks such as text classification, word/phrase similarity, test classification and sentiment analysis.
  \item \textbf{CSC sentence similarity}: This algorithm is an adaptation of the “closest vector problem” quantum algorithm to perform sentence similarity calculations in the distributional compositional framework. This algorithm is based on tensor product composition that gives a grammatically informed algorithm to compute meaning of sentences/phrases and stores the meanings in quantum systems.
\end{itemize}

The objective of this project is to implement the two quantum algorithms (“closest vector problem” and “sentence similarity”) of the DisCo model on the Intel Quantum Simulator (qHiPSTER). Given a corpus, the implemented solution aims to compute the meanings of two sentences (built from words in the corpus) and decide if their meanings match.

\subsection{Structure of the Document}
The rest of the document is structured as follows: Sections \ref{sec:abstraction_of_disco_algorithms} and \ref{sec:mapping_disco_algorithms_on_intel_quantum_simulator} present abstractions of the DisCo algorithms that maps them to the quantum Dirac notation and discusses the strategies for their implementation on the Intel qHiPSTER, respectively; Section \ref{sec:representative_corpora} presents the representative corpora that are used during the implementation of the algorithms for their testing and evaluation; Section \ref{sec:testing_and_evaluation_methodologies} summarises the methods that will be used to test and evaluate the implementation of the algorithms; Section \ref{sec:intel_quantum_simulator_on_kay} presents an overview of the Intel qHiPSTER installation on the Irish national super computer (Kay); Section \ref{sec:discussion_and_summary} summarises and discusses the next steps towards implementing the algorithms.